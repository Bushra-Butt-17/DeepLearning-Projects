# ğŸŒŸ Ultimate Deep Learning Projects: From Basics to Brilliance ğŸ§ 

![image](https://github.com/user-attachments/assets/60ef079f-335b-4df7-85bf-ce7d848b7d8c)



---

# Iris Classification ğŸŒ¸

This project demonstrates a deep learning model for classifying the **Iris** dataset, which contains three species of Iris flowers: Setosa, Versicolor, and Virginica. The dataset includes features such as sepal length, sepal width, petal length, and petal width for each species.

## Key Steps ğŸ”‘:

- **Data Preprocessing** ğŸ§¹: Clean the dataset and apply feature scaling to improve model performance.
- **Model Architecture** ğŸ—ï¸: Build a neural network using Keras for multi-class classification.
- **Training & Evaluation** ğŸ“Š: Train the model and evaluate its accuracy in classifying the Iris species.

## Key Insights ğŸ”:

- **Setosa's Distinct Sepal Length** ğŸ“: Setosa typically has shorter sepal lengths, which are clearly visible in the **distribution plot**.  

- **Overlap Between Versicolor and Virginica** ğŸ¤: These two species show some overlap in sepal length, but Virginica generally has longer sepals.  

- **Petal Length Distribution** ğŸŒº: Setosa has a narrow range of petal lengths, while Versicolor and Virginica have broader distributions. Virginica generally has longer petals.  

- **Pairplot Overview** ğŸ” : The **pairplot** shows that Setosa is easily distinguishable from Versicolor and Virginica, especially in terms of petal length and width, while Versicolor and Virginica overlap slightly.  

ğŸ‘‰ **[Explore the Full Project](https://github.com/Bushra-Butt-17/DeepLearning-Projects/tree/main/Iris-Data-Insights)**  

---

# ğŸ¡ Ames Housing Price Prediction: Linear Regression with Gradient Descent

This project demonstrates how to build a linear regression model from scratch using the **Ames Housing Dataset** ğŸ˜ï¸. It includes:  

- Implementing the **Gradient Descent algorithm** for optimizing model parameters.  
- Analyzing the data to gain insights and visualize trends.  
- Evaluating the model's performance using metrics like RMSE.  
- Visualizing results such as **learning curves** and feature impacts.  

The project is organized as follows:  

- **Main Notebook**: All analysis and code are consolidated in the `linear-regression-with-gd.ipynb` file.  
- **Dataset**: Located in the `data` directory as `Ames_Housing.csv`.  
- **Visualizations**: Plots and images are stored in the `visualizations` directory, showcasing learning curves and insights.  

ğŸ‘‰ **[Explore the Full Project](https://github.com/Bushra-Butt-17/DeepLearning-Projects/tree/main/Linear-Regression-with-GD)**  

Feel free to check out the directory structure, dive into the notebook, and explore how linear regression works with Gradient Descent! ğŸš€

---
# ğŸ¾ Logistic Regression with Neural Network: Cat Classifier  

## ğŸš€ Overview  
Classify ğŸ± vs. ğŸ¾ (non-cats) using **Logistic Regression** implemented from scratch. Understand core concepts like **forward propagation**, **backpropagation**, and **optimization**.  

## ğŸ—‚ï¸ Structure  
- **`datasets/`**: Training & testing images.  
- **`Logistic_Regression_with_Neural_Network.ipynb`**: Main notebook.  

## ğŸ”§ Requirements  
- `numpy`, `matplotlib`, `PIL`, `scikit-learn`  

## ğŸ§  Steps  
1. **Data Preprocessing**: Flatten & normalize images.  
2. **Training**: Update weights using gradient descent.  
3. **Evaluation**: Analyze accuracy & confusion matrix.  

## ğŸ“Š Results  
Evaluate performance with metrics like accuracy and visualize results.  

## ğŸ¯ Conclusion  
Build a simple yet effective neural network to classify cats while learning foundational ML concepts!

ğŸ‘‰ **[Explore the Full Project](https://github.com/Bushra-Butt-17/DeepLearning-Projects/tree/main/Logistic%20Regression)**  
---

# ğŸš€ **MLP Planar Data Classification**

---

This project demonstrates the power of **Multi-Layer Perceptron (MLP)** in classifying **planar data**, showcasing how neural networks can solve problems involving non-linearly separable datasets. With the help of **gradient descent optimization**, the MLP learns to create complex decision boundaries to classify the data points effectively.

- **Key Features** âœ¨:
  - **Planar Data Classification** using MLP ğŸ¤–: A hands-on approach to solving non-linearly separable classification tasks.
  - **Gradient Descent Optimization** ğŸ”„: The model learns by minimizing the binary cross-entropy loss function.
  - **Intuitive Visualizations** ğŸ“Š: Visualize the training process with plots like the decision boundary, loss curve, and accuracy progression, stored in the `Visualizations/` directory.
  - **Step-by-Step Implementation** ğŸ“: Detailed notebook with clear code comments for an educational understanding of MLP training.

- **Technical Insights** âš™ï¸:
  - **Activation Function**: Sigmoid ğŸŸ¢
  - **Loss Function**: Binary Cross-Entropy ğŸ“‰
  - **Optimizer**: Gradient Descent ğŸš´â€â™‚ï¸
  - **Metrics**: Accuracy ğŸ“ˆ and visualized decision boundaries for model evaluation.

- **Directory Structure** ğŸ“‚:
  - **Main Notebook**: `MLP-Planar-Data-Classification.ipynb` ğŸ“, where all the implementation takes place.
  - **Visualizations Directory**: Contains key plots to track model performance, such as:
    - **Decision Boundary** ğŸ”µğŸŸ 
    - **Loss Curve** ğŸ“‰
    - **Accuracy Progression** ğŸ“ˆ

- **Contributing** ğŸ¤: Contributions are encouraged! Fork the repo, submit issues, or create pull requests for improvements and enhancements.

- **Contact** ğŸ“§: For any questions or feedback, feel free to reach out!

--- 
