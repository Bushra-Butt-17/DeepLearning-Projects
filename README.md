# 🌟 Ultimate Deep Learning Projects: From Basics to Brilliance 🧠

![image](https://github.com/user-attachments/assets/60ef079f-335b-4df7-85bf-ce7d848b7d8c)



---

# Iris Classification 🌸

This project demonstrates a deep learning model for classifying the **Iris** dataset, which contains three species of Iris flowers: Setosa, Versicolor, and Virginica. The dataset includes features such as sepal length, sepal width, petal length, and petal width for each species.

## Key Steps 🔑:

- **Data Preprocessing** 🧹: Clean the dataset and apply feature scaling to improve model performance.
- **Model Architecture** 🏗️: Build a neural network using Keras for multi-class classification.
- **Training & Evaluation** 📊: Train the model and evaluate its accuracy in classifying the Iris species.

## Key Insights 🔍:

- **Setosa's Distinct Sepal Length** 📏: Setosa typically has shorter sepal lengths, which are clearly visible in the **distribution plot**.  

- **Overlap Between Versicolor and Virginica** 🤝: These two species show some overlap in sepal length, but Virginica generally has longer sepals.  

- **Petal Length Distribution** 🌺: Setosa has a narrow range of petal lengths, while Versicolor and Virginica have broader distributions. Virginica generally has longer petals.  

- **Pairplot Overview** 🔠: The **pairplot** shows that Setosa is easily distinguishable from Versicolor and Virginica, especially in terms of petal length and width, while Versicolor and Virginica overlap slightly.  

👉 **[Explore the Full Project](https://github.com/Bushra-Butt-17/DeepLearning-Projects/tree/main/Iris-Data-Insights)**  

---

# 🏡 Ames Housing Price Prediction: Linear Regression with Gradient Descent

This project demonstrates how to build a linear regression model from scratch using the **Ames Housing Dataset** 🏘️. It includes:  

- Implementing the **Gradient Descent algorithm** for optimizing model parameters.  
- Analyzing the data to gain insights and visualize trends.  
- Evaluating the model's performance using metrics like RMSE.  
- Visualizing results such as **learning curves** and feature impacts.  

The project is organized as follows:  

- **Main Notebook**: All analysis and code are consolidated in the `linear-regression-with-gd.ipynb` file.  
- **Dataset**: Located in the `data` directory as `Ames_Housing.csv`.  
- **Visualizations**: Plots and images are stored in the `visualizations` directory, showcasing learning curves and insights.  

👉 **[Explore the Full Project](https://github.com/Bushra-Butt-17/DeepLearning-Projects/tree/main/Linear-Regression-with-GD)**  

Feel free to check out the directory structure, dive into the notebook, and explore how linear regression works with Gradient Descent! 🚀

---
# 🐾 Logistic Regression with Neural Network: Cat Classifier  

## 🚀 Overview  
Classify 🐱 vs. 🐾 (non-cats) using **Logistic Regression** implemented from scratch. Understand core concepts like **forward propagation**, **backpropagation**, and **optimization**.  

## 🗂️ Structure  
- **`datasets/`**: Training & testing images.  
- **`Logistic_Regression_with_Neural_Network.ipynb`**: Main notebook.  

## 🔧 Requirements  
- `numpy`, `matplotlib`, `PIL`, `scikit-learn`  

## 🧠 Steps  
1. **Data Preprocessing**: Flatten & normalize images.  
2. **Training**: Update weights using gradient descent.  
3. **Evaluation**: Analyze accuracy & confusion matrix.  

## 📊 Results  
Evaluate performance with metrics like accuracy and visualize results.  

## 🎯 Conclusion  
Build a simple yet effective neural network to classify cats while learning foundational ML concepts!

👉 **[Explore the Full Project](https://github.com/Bushra-Butt-17/DeepLearning-Projects/tree/main/Logistic%20Regression)**  
---

# 🚀 **MLP Planar Data Classification**

---

This project demonstrates the power of **Multi-Layer Perceptron (MLP)** in classifying **planar data**, showcasing how neural networks can solve problems involving non-linearly separable datasets. With the help of **gradient descent optimization**, the MLP learns to create complex decision boundaries to classify the data points effectively.

- **Key Features** ✨:
  - **Planar Data Classification** using MLP 🤖: A hands-on approach to solving non-linearly separable classification tasks.
  - **Gradient Descent Optimization** 🔄: The model learns by minimizing the binary cross-entropy loss function.
  - **Intuitive Visualizations** 📊: Visualize the training process with plots like the decision boundary, loss curve, and accuracy progression, stored in the `Visualizations/` directory.
  - **Step-by-Step Implementation** 📝: Detailed notebook with clear code comments for an educational understanding of MLP training.

- **Technical Insights** ⚙️:
  - **Activation Function**: Sigmoid 🟢
  - **Loss Function**: Binary Cross-Entropy 📉
  - **Optimizer**: Gradient Descent 🚴‍♂️
  - **Metrics**: Accuracy 📈 and visualized decision boundaries for model evaluation.

- **Directory Structure** 📂:
  - **Main Notebook**: `MLP-Planar-Data-Classification.ipynb` 📝, where all the implementation takes place.
  - **Visualizations Directory**: Contains key plots to track model performance, such as:
    - **Decision Boundary** 🔵🟠
    - **Loss Curve** 📉
    - **Accuracy Progression** 📈

- **Contributing** 🤝: Contributions are encouraged! Fork the repo, submit issues, or create pull requests for improvements and enhancements.

- **Contact** 📧: For any questions or feedback, feel free to reach out!

--- 
